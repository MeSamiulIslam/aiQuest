{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVj29GjFUPfEmeXvrrE6US",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MeSamiulIslam/aiQuest/blob/main/Class_16_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Stemming"
      ],
      "metadata": {
        "id": "0kv27sRQmby3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "chqk4iMEjSTc",
        "outputId": "5c3b8392-ffac-47af-d3d8-d4e49c2d297a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Stemming follows an algorithm with steps to perform on the words which makes it faster. Whereas, in lemmatization, you used WordNet corpus and a corpus for stop words as well to produce lemma which makes it slower than stemming. You also had to define a parts-of-speech to obtain the correct lemma.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "word = 'Stemming follows an algorithm with steps to perform on the words which makes it faster. Whereas, in lemmatization, you used WordNet corpus and a corpus for stop words as well to produce lemma which makes it slower than stemming. You also had to define a parts-of-speech to obtain the correct lemma.'\n",
        "word"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5exzVz34j53e",
        "outputId": "111c8757-1e1c-42b9-aec5-e4de391dede8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "p = PorterStemmer()"
      ],
      "metadata": {
        "id": "0PTM7NGmkCN5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for w in word:\n",
        "  print(p.stem(w))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJpCeVeLkj2b",
        "outputId": "4ef95f71-9d97-4347-e6b2-642dd7100f96"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s\n",
            "t\n",
            "e\n",
            "m\n",
            "m\n",
            "i\n",
            "n\n",
            "g\n",
            " \n",
            "f\n",
            "o\n",
            "l\n",
            "l\n",
            "o\n",
            "w\n",
            "s\n",
            " \n",
            "a\n",
            "n\n",
            " \n",
            "a\n",
            "l\n",
            "g\n",
            "o\n",
            "r\n",
            "i\n",
            "t\n",
            "h\n",
            "m\n",
            " \n",
            "w\n",
            "i\n",
            "t\n",
            "h\n",
            " \n",
            "s\n",
            "t\n",
            "e\n",
            "p\n",
            "s\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "p\n",
            "e\n",
            "r\n",
            "f\n",
            "o\n",
            "r\n",
            "m\n",
            " \n",
            "o\n",
            "n\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "w\n",
            "o\n",
            "r\n",
            "d\n",
            "s\n",
            " \n",
            "w\n",
            "h\n",
            "i\n",
            "c\n",
            "h\n",
            " \n",
            "m\n",
            "a\n",
            "k\n",
            "e\n",
            "s\n",
            " \n",
            "i\n",
            "t\n",
            " \n",
            "f\n",
            "a\n",
            "s\n",
            "t\n",
            "e\n",
            "r\n",
            ".\n",
            " \n",
            "w\n",
            "h\n",
            "e\n",
            "r\n",
            "e\n",
            "a\n",
            "s\n",
            ",\n",
            " \n",
            "i\n",
            "n\n",
            " \n",
            "l\n",
            "e\n",
            "m\n",
            "m\n",
            "a\n",
            "t\n",
            "i\n",
            "z\n",
            "a\n",
            "t\n",
            "i\n",
            "o\n",
            "n\n",
            ",\n",
            " \n",
            "y\n",
            "o\n",
            "u\n",
            " \n",
            "u\n",
            "s\n",
            "e\n",
            "d\n",
            " \n",
            "w\n",
            "o\n",
            "r\n",
            "d\n",
            "n\n",
            "e\n",
            "t\n",
            " \n",
            "c\n",
            "o\n",
            "r\n",
            "p\n",
            "u\n",
            "s\n",
            " \n",
            "a\n",
            "n\n",
            "d\n",
            " \n",
            "a\n",
            " \n",
            "c\n",
            "o\n",
            "r\n",
            "p\n",
            "u\n",
            "s\n",
            " \n",
            "f\n",
            "o\n",
            "r\n",
            " \n",
            "s\n",
            "t\n",
            "o\n",
            "p\n",
            " \n",
            "w\n",
            "o\n",
            "r\n",
            "d\n",
            "s\n",
            " \n",
            "a\n",
            "s\n",
            " \n",
            "w\n",
            "e\n",
            "l\n",
            "l\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "p\n",
            "r\n",
            "o\n",
            "d\n",
            "u\n",
            "c\n",
            "e\n",
            " \n",
            "l\n",
            "e\n",
            "m\n",
            "m\n",
            "a\n",
            " \n",
            "w\n",
            "h\n",
            "i\n",
            "c\n",
            "h\n",
            " \n",
            "m\n",
            "a\n",
            "k\n",
            "e\n",
            "s\n",
            " \n",
            "i\n",
            "t\n",
            " \n",
            "s\n",
            "l\n",
            "o\n",
            "w\n",
            "e\n",
            "r\n",
            " \n",
            "t\n",
            "h\n",
            "a\n",
            "n\n",
            " \n",
            "s\n",
            "t\n",
            "e\n",
            "m\n",
            "m\n",
            "i\n",
            "n\n",
            "g\n",
            ".\n",
            " \n",
            "y\n",
            "o\n",
            "u\n",
            " \n",
            "a\n",
            "l\n",
            "s\n",
            "o\n",
            " \n",
            "h\n",
            "a\n",
            "d\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "d\n",
            "e\n",
            "f\n",
            "i\n",
            "n\n",
            "e\n",
            " \n",
            "a\n",
            " \n",
            "p\n",
            "a\n",
            "r\n",
            "t\n",
            "s\n",
            "-\n",
            "o\n",
            "f\n",
            "-\n",
            "s\n",
            "p\n",
            "e\n",
            "e\n",
            "c\n",
            "h\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "o\n",
            "b\n",
            "t\n",
            "a\n",
            "i\n",
            "n\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "c\n",
            "o\n",
            "r\n",
            "r\n",
            "e\n",
            "c\n",
            "t\n",
            " \n",
            "l\n",
            "e\n",
            "m\n",
            "m\n",
            "a\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "xGqCf4Alk41x"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-43cxBklOJr",
        "outputId": "4c328f87-a30c-4270-8483-5804bcf28979"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token = word_tokenize(word)\n",
        "token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHO_rRJKlZzq",
        "outputId": "a8e49632-5930-4e90-d688-799ae99c54cf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Stemming',\n",
              " 'follows',\n",
              " 'an',\n",
              " 'algorithm',\n",
              " 'with',\n",
              " 'steps',\n",
              " 'to',\n",
              " 'perform',\n",
              " 'on',\n",
              " 'the',\n",
              " 'words',\n",
              " 'which',\n",
              " 'makes',\n",
              " 'it',\n",
              " 'faster',\n",
              " '.',\n",
              " 'Whereas',\n",
              " ',',\n",
              " 'in',\n",
              " 'lemmatization',\n",
              " ',',\n",
              " 'you',\n",
              " 'used',\n",
              " 'WordNet',\n",
              " 'corpus',\n",
              " 'and',\n",
              " 'a',\n",
              " 'corpus',\n",
              " 'for',\n",
              " 'stop',\n",
              " 'words',\n",
              " 'as',\n",
              " 'well',\n",
              " 'to',\n",
              " 'produce',\n",
              " 'lemma',\n",
              " 'which',\n",
              " 'makes',\n",
              " 'it',\n",
              " 'slower',\n",
              " 'than',\n",
              " 'stemming',\n",
              " '.',\n",
              " 'You',\n",
              " 'also',\n",
              " 'had',\n",
              " 'to',\n",
              " 'define',\n",
              " 'a',\n",
              " 'parts-of-speech',\n",
              " 'to',\n",
              " 'obtain',\n",
              " 'the',\n",
              " 'correct',\n",
              " 'lemma',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for w0 in token:\n",
        "    print(p.stem(w0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HXP55suli9h",
        "outputId": "d3eddc13-718c-4dc3-ed76-5b3b0bea78e7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stem\n",
            "follow\n",
            "an\n",
            "algorithm\n",
            "with\n",
            "step\n",
            "to\n",
            "perform\n",
            "on\n",
            "the\n",
            "word\n",
            "which\n",
            "make\n",
            "it\n",
            "faster\n",
            ".\n",
            "wherea\n",
            ",\n",
            "in\n",
            "lemmat\n",
            ",\n",
            "you\n",
            "use\n",
            "wordnet\n",
            "corpu\n",
            "and\n",
            "a\n",
            "corpu\n",
            "for\n",
            "stop\n",
            "word\n",
            "as\n",
            "well\n",
            "to\n",
            "produc\n",
            "lemma\n",
            "which\n",
            "make\n",
            "it\n",
            "slower\n",
            "than\n",
            "stem\n",
            ".\n",
            "you\n",
            "also\n",
            "had\n",
            "to\n",
            "defin\n",
            "a\n",
            "parts-of-speech\n",
            "to\n",
            "obtain\n",
            "the\n",
            "correct\n",
            "lemma\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lemmatization"
      ],
      "metadata": {
        "id": "PwVAZORBmf8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lem = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "azR-TfIbmigU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFKtzBKTmy-r",
        "outputId": "3004686a-ef76-46e4-bfbf-303095ef09a3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0psC7y3Bm8S0",
        "outputId": "3cee7502-e940-46ff-9071-45fe1e2b9e97"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for w1 in token:\n",
        "  print('Before= ', w1, end = ' , ')\n",
        "  print('After= ', lem.lemmatize(w1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8g_gmPg7nCWs",
        "outputId": "328c885f-0118-4dca-84f6-88e8fac70bfe"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before=  Stemming , After=  Stemming\n",
            "Before=  follows , After=  follows\n",
            "Before=  an , After=  an\n",
            "Before=  algorithm , After=  algorithm\n",
            "Before=  with , After=  with\n",
            "Before=  steps , After=  step\n",
            "Before=  to , After=  to\n",
            "Before=  perform , After=  perform\n",
            "Before=  on , After=  on\n",
            "Before=  the , After=  the\n",
            "Before=  words , After=  word\n",
            "Before=  which , After=  which\n",
            "Before=  makes , After=  make\n",
            "Before=  it , After=  it\n",
            "Before=  faster , After=  faster\n",
            "Before=  . , After=  .\n",
            "Before=  Whereas , After=  Whereas\n",
            "Before=  , , After=  ,\n",
            "Before=  in , After=  in\n",
            "Before=  lemmatization , After=  lemmatization\n",
            "Before=  , , After=  ,\n",
            "Before=  you , After=  you\n",
            "Before=  used , After=  used\n",
            "Before=  WordNet , After=  WordNet\n",
            "Before=  corpus , After=  corpus\n",
            "Before=  and , After=  and\n",
            "Before=  a , After=  a\n",
            "Before=  corpus , After=  corpus\n",
            "Before=  for , After=  for\n",
            "Before=  stop , After=  stop\n",
            "Before=  words , After=  word\n",
            "Before=  as , After=  a\n",
            "Before=  well , After=  well\n",
            "Before=  to , After=  to\n",
            "Before=  produce , After=  produce\n",
            "Before=  lemma , After=  lemma\n",
            "Before=  which , After=  which\n",
            "Before=  makes , After=  make\n",
            "Before=  it , After=  it\n",
            "Before=  slower , After=  slower\n",
            "Before=  than , After=  than\n",
            "Before=  stemming , After=  stemming\n",
            "Before=  . , After=  .\n",
            "Before=  You , After=  You\n",
            "Before=  also , After=  also\n",
            "Before=  had , After=  had\n",
            "Before=  to , After=  to\n",
            "Before=  define , After=  define\n",
            "Before=  a , After=  a\n",
            "Before=  parts-of-speech , After=  parts-of-speech\n",
            "Before=  to , After=  to\n",
            "Before=  obtain , After=  obtain\n",
            "Before=  the , After=  the\n",
            "Before=  correct , After=  correct\n",
            "Before=  lemma , After=  lemma\n",
            "Before=  . , After=  .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lem.lemmatize('wants')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "pJiP5ceOnVfu",
        "outputId": "3bd9528f-dfaa-4c0c-a5bc-26ecdfaf7758"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'want'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Word2Vec"
      ],
      "metadata": {
        "id": "zNrno-tln9Xs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jYE-67In-cU",
        "outputId": "48cb8ad5-5bb8-4068-b91f-b29352cd9326"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.8/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.7.3)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (6.3.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec, KeyedVectors"
      ],
      "metadata": {
        "id": "oQL8vnsWoEk7"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "mxyMd1GGoR2U"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/MeSamiulIslam/aiQuest/main/data.csv'\n",
        "df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "bU1SGJ57oXg0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "SnBCSjYEpMLk",
        "outputId": "3ad49d5d-a1cf-450f-e086-4fa2f659aa46"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           test  class\n",
              "0             I love Bangladesh      1\n",
              "1  Could you give me an iphone?      0\n",
              "2            Hello how are you?      1\n",
              "3           I want to talk you.      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c49180f5-28ee-401b-aa95-a8cb852a2905\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I love Bangladesh</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Could you give me an iphone?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hello how are you?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I want to talk you.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c49180f5-28ee-401b-aa95-a8cb852a2905')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c49180f5-28ee-401b-aa95-a8cb852a2905 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c49180f5-28ee-401b-aa95-a8cb852a2905');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_vec = [nltk.word_tokenize(test) for test in df['test']]\n",
        "text_vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqRUp3G3pgHa",
        "outputId": "59813585-9371-4628-9b68-b765d05e4be8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['I', 'love', 'Bangladesh'],\n",
              " ['Could', 'you', 'give', 'me', 'an', 'iphone', '?'],\n",
              " ['Hello', 'how', 'are', 'you', '?'],\n",
              " ['I', 'want', 'to', 'talk', 'you', '.']]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Word2Vec(text_vec, min_count=1)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFXr2p_6p19C",
        "outputId": "48afdced-e0f2-46b3-d4af-7ad104e85e95"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.models.word2vec.Word2Vec at 0x7fd47481aa90>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar('Could')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4xCZU0IqK89",
        "outputId": "1ac85258-8432-4d00-b394-78ec4f89d48d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('want', 0.18553461134433746),\n",
              " ('give', 0.13699182868003845),\n",
              " ('iphone', 0.07545091956853867),\n",
              " ('talk', 0.061216991394758224),\n",
              " ('are', 0.04601741209626198),\n",
              " ('how', 0.021402813494205475),\n",
              " ('to', -0.00260976143181324),\n",
              " ('Bangladesh', -0.018741559237241745),\n",
              " ('an', -0.02395191788673401),\n",
              " ('.', -0.02881546877324581)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ApKn3fe_qZO8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}